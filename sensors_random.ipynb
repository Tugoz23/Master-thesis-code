{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file indlude the robusness analysis for the random selected sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pvlib\n",
    "from pvlib.irradiance import aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Østbirk=pd.read_csv(\"df_Østbirk_random.csv\")\n",
    "df_Malaga=pd.read_csv(\"Malaga_random.csv\")\n",
    "df_Monpellier=pd.read_csv(\"Data_Monpellier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Østbirk.shape)\n",
    "print(df_Malaga.shape)\n",
    "print(df_Monpellier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Monpellier.rename(columns={'Sash 15 mm below pane': 'Sash 15 mm below pane - aPV east' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data= pd.concat([df_Østbirk, df_Malaga,df_Monpellier], axis=0, ignore_index=True)\n",
    "df_APX= All_Data.drop(columns=[ 'Window_Type', 'Blinds'])\n",
    "print(df_APX.shape)\n",
    "print(df_APX.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_APX['Window_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = {\n",
    "    2: 'Malaga',\n",
    "    1: 'Østbirk',\n",
    "    8:'Montpellier' \n",
    "}\n",
    "def location_name(window_ID):\n",
    "    return locations.get(window_ID)\n",
    "\n",
    "df_APX[\"Location\"] = df_APX[\"Window_ID\"].apply(location_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX=df_APX.drop(columns=[\"Window_ID\"])\n",
    "df_APX['Time'] = pd.to_datetime(df_APX['Time'])\n",
    "df_APX=df_APX.set_index('Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX['Month'] =df_APX.index.month # extracts the month\n",
    "df_APX[\"day_of_year\"] = df_APX.index.dayofyear # extracts the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_APX[\"Month_sin\"] = np.sin(2 * np.pi * df_APX[\"Month\"] / 12) \n",
    "df_APX[\"Month_cos\"] = np.cos(2 * np.pi * df_APX[\"Month\"] / 12)\n",
    "\n",
    "df_APX[\"day_of_year_sin\"] = np.sin(2 * np.pi * df_APX[\"day_of_year\"] / 365)\n",
    "df_APX[\"day_of_year_cos\"] = np.cos(2 * np.pi * df_APX[\"day_of_year\"] / 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX[\"minute_of_day\"] =df_APX.index.hour * 60 + df_APX.index.minute\n",
    "\n",
    "# 1440 min = 24 hours\n",
    "df_APX[\"time_sin\"] = np.sin(2 * np.pi * df_APX[\"minute_of_day\"] / 1440)\n",
    "df_APX[\"time_cos\"] = np.cos(2 * np.pi * df_APX[\"minute_of_day\"] / 1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX=df_APX.reset_index('Time')\n",
    "# This function calculates the solar position\n",
    "def get_solar_position(row):\n",
    "    solpos = pvlib.solarposition.get_solarposition(row['Time'], row['Latitude'], row['Longitude'])\n",
    "    return pd.Series([solpos['azimuth'].values[0], solpos['apparent_elevation'].values[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX[['solar_azimuth', 'solar_elevation']] = df_APX.apply(get_solar_position, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX['solar_azimuth_sin'] = np.sin(np.deg2rad(df_APX['solar_azimuth']))\n",
    "df_APX['solar_azimuth_cos'] = np.cos(np.deg2rad(df_APX['solar_azimuth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX['window_tilt'] = df_APX['Location'].apply(\n",
    "    lambda loc: 45 if loc == 'Østbirk' else 23)\n",
    "\n",
    "df_APX['window_azimuth'] = df_APX.apply(\n",
    "    lambda row: 150 if row['Location'] == 'Montpellier' else (225 if row['Location'] == 'Østbirk' else 177), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX['solar_zenith']=  90 - df_APX['solar_elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the angle of incidence of the sun\n",
    "df_APX['aoi'] = aoi(\n",
    "    surface_tilt=df_APX['window_tilt'],\n",
    "    surface_azimuth=df_APX['window_azimuth'],\n",
    "    solar_zenith= df_APX['solar_zenith'],\n",
    "    solar_azimuth=df_APX['solar_azimuth']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX['cos_aoi'] = np.cos(np.radians(df_APX['aoi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APX=df_APX.drop(columns=['aoi','solar_zenith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29000, 76)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "df_APX= df_APX.set_index('Time')\n",
    "for loc, group in df_APX.groupby(\"Location\"):\n",
    "    group= group.asfreq('30min')\n",
    "    group[\"Location\"]=loc\n",
    "    df_list.append(group)\n",
    "    \n",
    "df_adjusted = pd.concat(df_list)\n",
    "print(df_adjusted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted=df_adjusted.reset_index()\n",
    "df_adjusted.loc[df_adjusted[\"Location\"] == 'Østbirk', \"Time\"] = df_adjusted.loc[df_adjusted[\"Location\"] == 'Østbirk', \"Time\"].apply(lambda x: x.replace(year=2024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted3=df_adjusted.copy()\n",
    "df_adjusted.to_csv('df_adjusted3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted=pd.read_csv('df_adjusted3.csv')\n",
    "df_adjusted['Time'] = pd.to_datetime(df_adjusted['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=['Cladding uPV east corner',\n",
    "       'Sash 15 mm below pane - bottom center', 'Gip uPV east',\n",
    "       'Outer pane spacer - top center', 'Gip uPV west corner',\n",
    "       'Outer frame lower - top center', 'Sash behind pane - aPV east',\n",
    "       'Inner frame uPV east', 'Inner pane spacer - bottom center',\n",
    "       'Sash gasket level - bottom center', \n",
    "       'Gip aPV west', 'Outer frame upper - uPV west', 'Gip uPV east corner',\n",
    "       'Sash 15 mm below pane - uPV east', 'Clading uPV west',\n",
    "       'Inner pane spacer - uPV east', 'Outer frame upper - uPV east',\n",
    "       'Sash gasket level - uPV east', 'Outer frame lower - uPV east',\n",
    "       'Gip Bottom Center', 'Gip Top Center', 'Clading aPV east',\n",
    "       'Sash 15 mm below pane - aPV east', 'Sash gasket level - aPV east',\n",
    "       'Outer frame upper - aPV west', 'Top frame aPV west',\n",
    "       'Top cladding - top center', 'Blind C room']\n",
    "dfs = []\n",
    "\n",
    "\n",
    "\n",
    "for loc, group in df_adjusted.groupby([\"Location\"],dropna=False):\n",
    "    location = loc[0]\n",
    "    for target in targets:\n",
    "        df_target = group.copy()\n",
    "        print(len(df_target))\n",
    "        df_target = df_target.drop(columns=[t for t in targets if t != target])\n",
    "        df_target = df_target.rename(columns={target: \"sensor_temp\"})\n",
    "        df_target[\"sensor_ID\"] = target\n",
    "        df_target[\"timeserie_ID\"] =f\"{location}, {target}\"\n",
    "        dfs.append(df_target)\n",
    "\n",
    "# Kombinér alt til ét dataframe\n",
    "df_global_long_form3 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_long_form3 = df_global_long_form3.dropna(subset='sensor_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_long_form3.to_csv(\"global_dataset3.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_long_form = pd.read_csv(\"global_dataset3.csv\",index_col=0)\n",
    "df_global_long_form['Time']= pd.to_datetime(df_global_long_form[\"Time\"])\n",
    "\n",
    "\n",
    "df_global_long_form = df_global_long_form.set_index('Time')\n",
    "\n",
    "df_filtered_timeserie3 = df_global_long_form[~((df_global_long_form['Location'] == 'Montpellier') & (df_global_long_form.index > '2024-12-17'))]\n",
    "\n",
    "\n",
    "\n",
    "df_filtered_timeserie3.to_csv(\"df_filtered_timeserie3.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_timeserie= pd.read_csv(\"df_filtered_timeserie3.csv\",index_col=0)\n",
    "df_filtered_timeserie.index= pd.to_datetime(df_filtered_timeserie.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_data_by_half_months(df):\n",
    "    # Fold 1\n",
    "    fold1_train = df[df.index.month.isin([5, 6, 7]) | ((df.index.month == 8) & (df.index.day <= 15))]\n",
    "    fold1_valid = df[(df.index.month == 8) & (df.index.day > 15)]\n",
    "    \n",
    "    # Fold 2\n",
    "    fold2_train = df[df.index.month.isin([5, 6, 7, 8]) | ((df.index.month == 9) & (df.index.day <= 15))]\n",
    "    fold2_valid = df[(df.index.month == 9) & (df.index.day > 15)]\n",
    "    \n",
    "    # Fold 3\n",
    "    fold3_train = df[df.index.month.isin([5, 6, 7, 8, 9]) | ((df.index.month == 10) & (df.index.day <= 15))]\n",
    "    fold3_valid = df[(df.index.month == 10) & (df.index.day > 15)]\n",
    "    fold_4 = df[df.index.month.isin([5, 6, 7, 8, 9,10]) | ((df.index.month == 11) & (df.index.day <= 15))]\n",
    "    \n",
    "    test = df[df.index.month.isin([12,1]) | ((df.index.month == 11) & (df.index.day > 15))]\n",
    "    \n",
    "    return [\n",
    "        (fold1_train, fold1_valid),\n",
    "        (fold2_train, fold2_valid),\n",
    "        (fold3_train, fold3_valid)\n",
    "    ],fold_4, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensures uniform time frequency\n",
    "resampled_groups = []\n",
    "for ts_id, group in df_filtered_timeserie.groupby('timeserie_ID'):\n",
    "\n",
    "    group_asfreq = group.asfreq(\"30min\")\n",
    "\n",
    "    group_asfreq['timeserie_ID'] = ts_id\n",
    "\n",
    "    resampled_groups.append(group_asfreq)\n",
    "\n",
    "df_resampled = pd.concat(resampled_groups)\n",
    "df_filtered_timeserie=df_resampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df_filtered_timeserie.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['window_area'] = df['Location'].apply(\n",
    "    lambda loc: 118*78 if loc == 'Montpellier' else 140*78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_exogenes(dataframe,eksogene_variables,lag_sizes):\n",
    "    df=dataframe.copy()   \n",
    "    for col in eksogene_variables:    \n",
    "        for lag in lag_sizes:\n",
    "            df[f'lag_{lag,col}'] = df[col].shift(lag)\n",
    "    \n",
    "    df=df.dropna()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_long_form_subset=df.drop(columns=['Location','Month','ET','day_of_year','minute_of_day','THW Index','In Dew','UV Dose','Wind Run','Bar','Heat D-D', 'Cool D-D','In Hum',\n",
    "                                                            'Wind Dir','Hi Dir','window_azimuth','window_tilt','Rain', 'Rain Rate','Hi Temp','Low Temp','Hi Solar Rad.', \n",
    "                                                            'Hi Speed','solar_azimuth','Wind Chill','Hi UV','Heat Index','In Heat','UV Index','THSW Index'])\n",
    "                            \n",
    "                                                \n",
    "\n",
    "                            \n",
    "                                                \n",
    "\n",
    "numerical=['Temp Out', 'Solar Rad.',\n",
    "    'In Temp','cos_aoi','Out Hum',\n",
    "    'Wind Speed','Dew Pt.']\n",
    "\n",
    "df_list = []\n",
    "for ts, group in df_global_long_form_subset.groupby([\"timeserie_ID\"],dropna=False):\n",
    "    print(group.shape)\n",
    "    group = create_features_exogenes(\n",
    "        dataframe=group,\n",
    "        eksogene_variables= numerical,\n",
    "        lag_sizes=[1,2,3,4,5],\n",
    "        )\n",
    "   \n",
    "    df_list.append(group)\n",
    "\n",
    "df_window = pd.concat(df_list)\n",
    "\n",
    "print(df_window.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params={'n_estimators': 1251, 'learning_rate': 0.02112537357198592, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6328513694770547, 'colsample_bytree': 0.6953877485019768, 'reg_alpha': 5.413621183560153, 'reg_lambda': 0.5884116397695999, 'gamma': 3.3650674471559303}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expanding_splits,train_all, test = split_data_by_half_months(df_window)\n",
    "\n",
    "final_model = XGBRegressor(**best_params,random_state=42,enable_categorical =True)\n",
    "final_train_set = train_all\n",
    "\n",
    "\n",
    "target=['sensor_temp']\n",
    "targets=['sensor_temp','timeserie_ID']\n",
    "\n",
    "X_train_final, y_train_final = final_train_set.drop(columns=targets), final_train_set[target]\n",
    "X_test, y_test = test.drop(columns=targets), test[target]\n",
    "\n",
    "X_train_final['sensor_ID']=X_train_final['sensor_ID'].astype('category')\n",
    "X_test['sensor_ID']=X_test['sensor_ID'].astype('category')\n",
    "\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "y_train_pred= final_model.predict(X_train_final)\n",
    "mse = mean_squared_error(y_train_final, y_train_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "mae= mean_absolute_error(y_train_final, y_train_pred)\n",
    "\n",
    "print(\"Train mse:\",mse)\n",
    "print(\"Train rmse:\",rmse)\n",
    "print(\"Train mae:\", mae)\n",
    "\n",
    "    \n",
    "\n",
    "y_test_pred= final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "mae= mean_absolute_error(y_test,y_test_pred)\n",
    "\n",
    "print(\"Test mse:\",mse)\n",
    "print(\"Test rmse:\",rmse)\n",
    "print(\"Test mae:\", mae)\n",
    "\n",
    "\n",
    "\n",
    "results_df=[]\n",
    "for ts in test[\"timeserie_ID\"].unique():\n",
    "  \n",
    "    mask = test[\"timeserie_ID\"] == ts\n",
    "    y_true = y_test[mask]\n",
    "    y_pred = y_test_pred[mask]\n",
    "        \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    " \n",
    "    results_df.append({\"Timeserie\": ts, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae})\n",
    "\n",
    "   \n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_true.index, y_true, label=\"True values\", linestyle='-')\n",
    "    plt.plot(y_true.index, y_pred, label=\"Preicted Values\", linestyle='-', alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(f\"Temperature\")\n",
    "    plt.title(f\"True value vs. predicted for {ts}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "        \n",
    "results_df = pd.DataFrame(results_df)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
